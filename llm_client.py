"""
LLM æµå¼è°ƒç”¨å®¢æˆ·ç«¯
ä½¿ç”¨ httpx å‘é€ OpenAI å…¼å®¹æ ¼å¼çš„æµå¼è¯·æ±‚ï¼Œæ”¯æŒä¼ å…¥ä¸Šä¸‹æ–‡
"""

import json
import httpx
from PyQt6.QtCore import QThread, pyqtSignal


class LLMStreamWorker(QThread):
    """
    åœ¨åå°çº¿ç¨‹ä¸­è°ƒç”¨ LLM APIï¼Œé€ token å‘é€ç»™ UIã€‚

    ä¿¡å·ï¼š
      token_received(str)  - æ¯æ”¶åˆ°ä¸€æ®µæ–°æ–‡æœ¬æ—¶å‘å°„
      stream_finished()    - æµå¼è¾“å‡ºå®Œæˆ
      error_occurred(str)  - å‡ºé”™æ—¶å‘å°„é”™è¯¯ä¿¡æ¯
    """

    token_received = pyqtSignal(str)
    stream_finished = pyqtSignal()
    error_occurred = pyqtSignal(str)

    def __init__(
        self,
        api_key: str,
        api_base_url: str,
        model_name: str,
        prompt: str,
        user_text: str,
        context: str = "",
        parent=None,
    ):
        super().__init__(parent)
        self.api_key = api_key
        self.api_base_url = api_base_url.rstrip("/")
        self.model_name = model_name
        self.prompt = prompt
        self.user_text = user_text
        self.context = context
        self._cancelled = False

    def cancel(self):
        self._cancelled = True

    def run(self):
        # ç»„è£… Promptï¼šæ›¿æ¢å ä½ç¬¦
        full_prompt = self.prompt.replace("{text}", self.user_text)
        full_prompt = full_prompt.replace("{context}", self.context)

        messages = [{"role": "user", "content": full_prompt}]

        url = f"{self.api_base_url}/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": self.model_name,
            "messages": messages,
            "stream": True,
        }

        try:
            with httpx.Client(timeout=60.0) as client:
                with client.stream(
                    "POST", url, headers=headers, json=payload
                ) as response:
                    if response.status_code != 200:
                        error_body = response.read().decode("utf-8", errors="replace")
                        if response.status_code == 401:
                            self.error_occurred.emit(
                                "API å¯†é’¥å¥½åƒå¡«é”™äº†å“¦ï¼Œè¯·å»å³ä¸‹è§’è®¾ç½®é‡Œæ£€æŸ¥ä¸€ä¸‹ ğŸ”‘"
                            )
                        elif response.status_code == 404:
                            self.error_occurred.emit(
                                f"æ¨¡å‹ '{self.model_name}' ä¸å­˜åœ¨ï¼Œè¯·åœ¨è®¾ç½®ä¸­æ£€æŸ¥æ¨¡å‹åç§° ğŸ¤”"
                            )
                        else:
                            self.error_occurred.emit(
                                f"è¯·æ±‚å¤±è´¥ (HTTP {response.status_code})ï¼š{error_body[:200]}"
                            )
                        return

                    for line in response.iter_lines():
                        if self._cancelled:
                            return
                        if not line or not line.startswith("data: "):
                            continue
                        data_str = line[6:]
                        if data_str.strip() == "[DONE]":
                            break
                        try:
                            chunk = json.loads(data_str)
                            delta = chunk.get("choices", [{}])[0].get("delta", {})
                            content = delta.get("content", "")
                            if content:
                                self.token_received.emit(content)
                        except json.JSONDecodeError:
                            continue

            if not self._cancelled:
                self.stream_finished.emit()

        except httpx.ConnectError:
            self.error_occurred.emit(
                "æ— æ³•è¿æ¥åˆ° AI æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– API åœ°å€æ˜¯å¦æ­£ç¡® ğŸŒ"
            )
        except httpx.TimeoutException:
            self.error_occurred.emit("è¯·æ±‚è¶…æ—¶ï¼ŒAI æœåŠ¡å™¨å“åº”å¤ªæ…¢äº† â±ï¸")
        except Exception as e:
            self.error_occurred.emit(f"å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{str(e)}")
